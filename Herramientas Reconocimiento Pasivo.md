<h1 align="center">ÍNDICE DE LAS HERRAMIENTAS QUE UTILIZAREMOS</h1>

**\- host** (dns)

**\- robots.txt** (directorios ocultos en la web)

**\- sitemaps.xml** (urls del sitio en la web)

**\- Extensiones en el navegador** (Wappanalyzer y buitwith)

**\- Httrack** (Descargar web)

**\- whois** (info de la web)

**\- theHavaster** (info de la web)

**\-netcraft** (info online de la web)

**\- dnsrecon** (traducción dns del dominio en kali)

**\- dnsdupster** (traducción dns del dominio online)

**\- wafw00f** (proxys y antivirus en la web)

**\- sublist3r** (muestra subdominios)

**\- Google dorking** (filtrar busquedas en google)

**\- have i been pwned** (contraseñas filtradas)

![image](https://github.com/user-attachments/assets/ee444536-2ff3-4d48-ae77-5dd57ee479d4)

<h1 align="center">Reconocimiento pasivo</h1>

![image](https://github.com/user-attachments/assets/757cb7a4-d84a-40cc-ac04-09ab3b45cfd3)

El reconocimiento pasivo trata de recopilar la mayor información posible a través de fuentes públicas en internet, sin interactuar directamente con el objetivo

# HOST

Lo primero que hay que hacer cuando queremos vulnerar una web es conseguir saber cuál es la dirección IP que está detrás de ese nombre de dominio. Para eso tenemos el comando host que realiza la traducción de dns:

![image](https://github.com/user-attachments/assets/c30254e9-32c3-4c2e-83d6-8c13ba694422)

Podemos ver que hay dos IPs detrás del nombre, eso quiere decir que contiene un firewall o proxy.

# ROBOTS.TXT

El mejor sitio para empezar a buscar información sobre la página es robots.txt. Contiene información de las carpetas o archivos que no quieres tener publicos

![image](https://github.com/user-attachments/assets/13e8123f-466b-4b96-b509-6c2de57f1aed)

Podemos comprobar que la pagina corre en wordpress y que no se puede visitar el directorio wp-admin

# SITEMAP.XML / SITEMAPS.XML

Es un archivo que los sitios web utilizan para proporcionar información a los motores de búsqueda sobre las páginas disponibles para rastrear en ese sitio web. Les agiliza el proceso de búsqueda.

Lo podemos utilizar para buscar información sobre los sitios públicos que tiene la web

# EXTENSIONES DEL NAVEGADOR PARA INFO DE LA WEB

Para analizar qué servicios corren detrás de la web existen extensiones como: BUILTWITH o WAPPALYZER. También tenemos el comando “whatweb”

# HTTRACK.COM

Es una herramienta que te permite descargar un sitio web a tu máquina local proporcionando los directorios de forma recursiva, archivos html, imágenes…

Se instala con:

- `sudo apt-get install webhttrack`

Cuando hacemos click en el programa se abre en el navegador

# WHOIS

El comando whois y la pagina web who.is te proporciona información sobre el sitio web:

# theHARVESTER

Es una herramienta parecida a sublist3r, recopila información de un sitio web que está publica en internet: correos electrónicos, nombres de empleados, subdominios, direcciones IP…

Uso:

- `theHarvester -d ine.com -b google,Linkedin`

# NETCRAFT

Una herramienta online que se utiliza mucho para obtener información de forma pasiva, recopila todo lo que recopilan las anteriores herramientas juntas:
![image](https://github.com/user-attachments/assets/7ce5fa74-1025-4c8b-9b57-ba50d4a7ddbf)

# DNSRECON

Herramienta de kali linux que proporciona información sobre que IPs se encuentran detras de los nombres de dominio.

- `dnsrecon -d hackersploit.org`

![image](https://github.com/user-attachments/assets/26b29476-bbb5-4f16-93fd-3c72282b5792)

Como podemos ver en las últimas líneas, el ns (name-server) es cloudflare, que es el proxy que utiliza la página.

También podemos ver la dirección que apunta nombre de dominio, que también corresponden al proxy de cloudflare:  

![image](https://github.com/user-attachments/assets/674cae68-4723-4318-ac5b-060a3249e4e8)

Y el servidor de correo que utiliza la web:

![image](https://github.com/user-attachments/assets/03f220bd-3f2b-429b-82c2-48e19c39fd0e)

# DNSDUPSTER

Es una herramienta online, similar a DNSRECON, que proporciona la misma información bien organizada. Puede mostrar los subdominios de un sitio web

# WAF ENUMERATION (WEB APPLICATION FIREWALL) —> wafw00f

Es una herramienta que sirve para detectar si hay un firewall o web application firewall protegiendo una web. Se descarga desde github. Manda una petición http y analiza la respuesta:

- `wafw00f hackersploit.org -a`

\-a: Análisis avanzado

![image](https://github.com/user-attachments/assets/c95bc9bf-04dd-4e7a-b99f-fc06d3e794eb)

Podemos ver que la página web utiliza cloudflare como web application firewall.

Esto quiere decir que cuando hacemos un dnsrecon la IP que nos proporciona es la del WAF. Si no detecta un WAF al hacer el reconocimiento dns la IP que nos proporciona seguramente será del servidor web

# SUBDOMAIN ENUMERATION —> SUBLIST3R

Esta herramienta sirve para enumerar los subdominios que puede contener un sitio web a través de la información que esta publica en internet (Google,bing, netcraft, dnsdumpster).

## Descarga:

- `sudo apt-get install sublist3r`

## Uso:

- `sublist3r -d hackersploit.org -e google,yahoo`

# GOOGLE DORKS / GOOGLE HACKING

Sirve para recopilar información pública sobre un sitio web a través de búsquedas concretas en google. Las búsquedas se realizan en el navegador y se utilizan una especie de filtros para encontrar la información concreta que buscamos. En Google Hacking Database ejemplos de uso de Google Dorks.

## Uso:

Para que solo me aparezcan los resultados de la búsqueda de un sitio web concreto:

- `site:ine.com`

Para buscar resultados específicos dentro de la url que estamos buscando, por ejemplo: un panel de administrador o un foro:

- `site:ine.com inurl:admin`

- `site:ine.com inurl:forum`

Para enumerar subdominios:

- `site:*.ine.com`

Para enumerar subdominios que en el título contengan la palabra admin:

- `site:*.ine.com intitle:admin`

Para enumerar subdominios con que contengan un tipo de archivo específico:

`site:*.ine.com filetype:pdf`

Para enumerar dominios que tengan una palabra específica:

- `site:ine.com employees`

Para enumerar sitios que tengan habilitado el listado de directorios

- `intitle:index of`

Cuando usas cache:, Google te muestra la última versión guardada de la página web desde sus servidores. Esto puede ser útil si la página original está temporalmente fuera de servicio, ha sido eliminada, o ha cambiado de manera significativa y necesitas ver cómo era antes.
(En la pagina waybackmachine se almacenan snapshots de los cambios de las webs)

- `cache:ine.com`

Para comprobar que un sitio web tiene público un directorio que expone las contraseñas:

- `inurl:auth_user_file`

- `inurl:password.txt`

# LEAKED PASSWORDS DATABASES: —> HAVE I BEEN PWNED

Muestra información sobre las filtraciones de contraseñas vinculadas a correos electrónicos, contraseñas filtradas, números de teléfono… en las páginas más conocidas
